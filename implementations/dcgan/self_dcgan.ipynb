{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_dcgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "IQ3pzbKKYj15",
        "gZd0PC8ddn6a"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qXRAKEQFaPy8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Self DCGAN\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/HighCWu/SelfGAN/blob/master/implementations/dcgan/self_dcgan.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/HighCWu/SelfGAN/blob/master/implementations/dcgan/self_dcgan.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "7dwNY7Ye7MX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ]
    },
    {
      "metadata": {
        "id": "SapDtrPf7Lrh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "\n",
        "        self.files = sorted(glob.glob(root + '/**/*.*', recursive=True))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.open(self.files[index % len(self.files)]).convert('RGB')\n",
        "        w, h = img.size\n",
        "\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKiW6WoRcHGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ]
    },
    {
      "metadata": {
        "id": "iv57iXGFL1iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "os.makedirs('images_normal', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iust7u4wTi4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')\n",
        "parser.add_argument('--batch_size', type=int, default=64, help='size of the batches')\n",
        "parser.add_argument('--lr', type=float, default=2e-4, help='adam: learning rate')\n",
        "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
        "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
        "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
        "parser.add_argument('--latent_dim', type=int, default=100, help='dimensionality of the latent space')\n",
        "parser.add_argument('--img_size', type=int, default=64, help='size of each image dimension')\n",
        "parser.add_argument('--channels', type=int, default=3, help='number of image channels')\n",
        "parser.add_argument('--sample_interval', type=int, default=200, help='interval betwen image samples')\n",
        "parser.add_argument('--data_use', type=str, default='bedroom', help='datasets:[mnist]/[bedroom]')\n",
        "\n",
        "opt, _ = parser.parse_known_args()\n",
        "if opt.data_use == 'mnist':\n",
        "  opt.img_size = 32\n",
        "  opt.channels = 1\n",
        "print(opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fzn0eKRx1a8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "from google.colab import files\n",
        "\n",
        "if opt.data_use == 'bedroom':\n",
        "    os.makedirs('data/bedroom', exist_ok=True)\n",
        "    print('Please upload your kaggle api json.')\n",
        "    files.upload()\n",
        "\n",
        "    ! mkdir /root/.kaggle\n",
        "    ! mv ./kaggle.json /root/.kaggle\n",
        "    ! chmod 600 /root/.kaggle/kaggle.json\n",
        "    ! kaggle datasets download -d jhoward/lsun_bedroom\n",
        "\n",
        "    out_fname = 'lsun_bedroom.zip'\n",
        "    zip_ref = zipfile.ZipFile(out_fname)\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "    os.remove(out_fname)\n",
        "\n",
        "    out_fname = 'sample.zip'\n",
        "    zip_ref = zipfile.ZipFile(out_fname)\n",
        "    zip_ref.extractall('data/bedroom/')\n",
        "    zip_ref.close()\n",
        "    os.remove(out_fname)\n",
        "else:\n",
        "    os.makedirs('data/mnist', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ng6pkwk6Vq5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLPXMaDWXeMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128*self.init_size**2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [   nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                        nn.LeakyReLU(0.2, inplace=True),\n",
        "                        nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2**4\n",
        "        self.adv_layer = nn.Sequential( nn.Linear(128*ds_size**2, 1),\n",
        "                                        nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity\n",
        "      \n",
        "class SelfGAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SelfGAN, self).__init__()\n",
        "\n",
        "        # Initialize generator and discriminator\n",
        "        self.generator = Generator()\n",
        "        self.discriminator = Discriminator()\n",
        "\n",
        "    def forward(self, z, real_img, fake_img):\n",
        "        gen_img = self.generator(z)\n",
        "        validity_gen = self.discriminator(gen_img)\n",
        "        validity_real = self.discriminator(real_img)\n",
        "        validity_fake = self.discriminator(fake_img)\n",
        "\n",
        "        return gen_img, validity_gen, validity_real, validity_fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iiRxa6X0df0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SelfGAN Part"
      ]
    },
    {
      "metadata": {
        "id": "jsGndq9kXx6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "shard_adversarial_loss = torch.nn.BCELoss(reduction='none')\n",
        "\n",
        "# Initialize SelfGAN model\n",
        "self_gan = SelfGAN()\n",
        "\n",
        "if cuda:\n",
        "    self_gan.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    shard_adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "self_gan.apply(weights_init_normal)  \n",
        "\n",
        "# Configure data loader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    ImageDataset('data/bedroom',\n",
        "                 transforms_=[\n",
        "                     transforms.Resize((opt.img_size, opt.img_size)),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                 ]) if opt.data_use == 'bedroom' else\n",
        "    datasets.MNIST('data/mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.Resize(opt.img_size),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                   ])),\n",
        "    batch_size=opt.batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "# Optimizers\n",
        "optimizer = torch.optim.Adam(self_gan.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "last_imgs = Tensor(opt.batch_size, *img_shape)*0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvoxGtZJYhoJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Standard performance on the GPU"
      ]
    },
    {
      "metadata": {
        "id": "jENYgMC5eDER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, imgs in enumerate(dataloader):\n",
        "        \n",
        "        if opt.data_use != 'bedroom':\n",
        "            imgs = imgs[0]\n",
        "            \n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train SelfGAN\n",
        "        # -----------------\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs, validity_gen, validity_real, validity_fake = self_gan(z, real_imgs, last_imgs)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator and measure discriminator's ability to classify real from generated samples at the same time\n",
        "        gen_loss = adversarial_loss(validity_gen, valid)\n",
        "        real_loss = adversarial_loss(validity_real, valid)\n",
        "        fake_loss = adversarial_loss(validity_fake, fake)\n",
        "        v_g = 1 - torch.mean(validity_gen)\n",
        "        v_f = torch.mean(validity_fake)\n",
        "        s_loss = (real_loss + v_g*gen_loss*0.1 + v_f*fake_loss*0.9) / 2\n",
        "\n",
        "        s_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        last_imgs = gen_imgs.detach()\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "        print (\"\\r[Epoch %d/%d] [Batch %d/%d] [S loss: %f  R loss: %f  F loss: %f  G loss: %f]\" % (epoch, opt.n_epochs, i, len(dataloader),\n",
        "                                                            s_loss.item(), real_loss.item(), fake_loss.item(), gen_loss.item()),\n",
        "              end='')\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            save_image(gen_imgs.data[:25], 'images/%d.png' % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQ3pzbKKYj15",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Running on the GPU with similar performance of running on the TPU (Maybe)"
      ]
    },
    {
      "metadata": {
        "id": "_D42DAmMYmFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, imgs in enumerate(dataloader):\n",
        "      \n",
        "        if opt.data_use != 'bedroom':\n",
        "            imgs = imgs[0]\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train SelfGAN\n",
        "        # -----------------\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        s = opt.batch_size//8\n",
        "        for k in range(8):\n",
        "          # Generate a batch of images\n",
        "          gen_imgs, validity_gen, validity_real, validity_fake = self_gan(z[k*s:k*s+s], real_imgs[k*s:k*s+s], last_imgs[k*s:k*s+s])\n",
        "\n",
        "          # Loss measures generator's ability to fool the discriminator and measure discriminator's ability to classify real from generated samples at the same time\n",
        "          gen_loss = shard_adversarial_loss(validity_gen, valid[k*s:k*s+s])\n",
        "          real_loss = shard_adversarial_loss(validity_real, valid[k*s:k*s+s])\n",
        "          fake_loss = shard_adversarial_loss(validity_fake, fake[k*s:k*s+s])\n",
        "          v_g = 1 - torch.mean(validity_gen)\n",
        "          v_r = 1 - torch.mean(validity_real)\n",
        "          v_f = torch.mean(validity_fake)\n",
        "          v_sum = v_g + v_r + v_f\n",
        "          s_loss = v_r*real_loss/v_sum + v_g*gen_loss/v_sum + v_f*fake_loss/v_sum\n",
        "          \n",
        "          gen_loss = torch.mean(gen_loss)\n",
        "          real_loss = torch.mean(real_loss)\n",
        "          fake_loss = torch.mean(fake_loss)\n",
        "          s_loss = torch.mean(s_loss)\n",
        "\n",
        "          s_loss.backward()\n",
        "          last_imgs[k*s:k*s+s] = gen_imgs.detach()\n",
        "          \n",
        "        optimizer.step()\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "        print (\"\\r[Epoch %d/%d] [Batch %d/%d] [S loss: %f  R loss: %f  F loss: %f  G loss: %f]\" % (epoch, opt.n_epochs, i, len(dataloader),\n",
        "                                                            s_loss.item(), real_loss.item(), fake_loss.item(), gen_loss.item()),\n",
        "              end='')\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            save_image(last_imgs.data[:25], 'images/%d.png' % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZd0PC8ddn6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normal GAN Part"
      ]
    },
    {
      "metadata": {
        "id": "dv8ovPfrdsaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)    \n",
        "    \n",
        "# Configure data loader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    ImageDataset('data/bedroom',\n",
        "                 transforms_=[\n",
        "                     transforms.Resize((opt.img_size, opt.img_size)),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                 ]) if opt.data_use == 'bedroom' else\n",
        "    datasets.MNIST('data/mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.Resize(opt.img_size),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                   ])),\n",
        "    batch_size=opt.batch_size, shuffle=True)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlmNSQ2Odykq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, imgs in enumerate(dataloader):\n",
        "      \n",
        "        if opt.data_use != 'bedroom':\n",
        "            imgs = imgs[0]\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "        print (\"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, opt.n_epochs, i, len(dataloader),\n",
        "                                                            d_loss.item(), g_loss.item()), \n",
        "               end='')\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            save_image(gen_imgs.data[:25], 'images_normal/%d.png' % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}