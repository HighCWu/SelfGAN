{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_dcgan_keras_tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mUaJMUDUezt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Self DCGAN Keras TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/HighCWu/SelfGAN/blob/master/implementations/dcgan/self_dcgan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/HighCWu/SelfGAN/blob/master/implementations/dcgan/self_dcgan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "_sFEKpmpesjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install 'tensorflow>1.12,<2.0' -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHK5Y87sVWAa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ]
    },
    {
      "metadata": {
        "id": "yg6TxwMvVVKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import threading\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.python.keras.utils import Sequence\n",
        "from tensorflow.python.keras.utils.data_utils import OrderedEnqueuer\n",
        "\n",
        "class ImageDataset:\n",
        "  \n",
        "    def __init__(self, root):\n",
        "\n",
        "        self.files = sorted(glob.glob(root + '/**/*.*', recursive=True))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.open(self.files[index % len(self.files)]).convert('RGB' if channels==3 else 'L')\n",
        "        w, h = img.size\n",
        "        img = img.resize((img_rows, img_cols), Image.LANCZOS)\n",
        "        img = np.asarray(img)\n",
        "        img = img/255*2 - 1\n",
        "        if channels==1:\n",
        "            img = img.reshape(img.shape+(1,))\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "      \n",
        "class DataLoader:\n",
        "    \n",
        "    def __init__(self, dataset, batch_size, workers=1, max_queue_size=10, cache_filepath='tmp/cache.h5', pool_size=64000):\n",
        "        self.idx = 0\n",
        "        bsz = batch_size\n",
        "        batch_pool = pool_size // bsz\n",
        "        self.length = batch_pool\n",
        "        \n",
        "        os.makedirs(os.path.dirname(cache_filepath), exist_ok=True)\n",
        "        cache_file = h5py.File(cache_filepath, 'w')\n",
        "        counter = {'i': 0, 'full': False}\n",
        "        def data_reader(counter, cache_file):\n",
        "          idx = 0\n",
        "          while True:\n",
        "            try:\n",
        "              X=[]\n",
        "              for i in range(bsz):\n",
        "                x = dataset[idx]\n",
        "                X.append(x)\n",
        "                idx = (idx + 1) % len(dataset)\n",
        "\n",
        "              if not counter['full']:\n",
        "                cache_file.create_dataset('x/{}'.format(counter['i']), data=X)\n",
        "              else:\n",
        "                cache_file['x/{}'.format(counter['i'])][...] = X\n",
        "              counter['i'] = (counter['i']+1)%(batch_pool)\n",
        "              if counter['i'] == 0:\n",
        "                counter['full'] = True\n",
        "              time.sleep(0.5)\n",
        "            except Exception as e:\n",
        "              raise e\n",
        "\n",
        "        dt = threading.Thread(target=data_reader, args=(counter, cache_file))\n",
        "        dt.start()\n",
        "        while counter['i'] < 100:\n",
        "          sys.stdout.flush()\n",
        "          print('\\rWaiting for enough cache.%d/100'%counter['i'], end='')\n",
        "        print('')\n",
        "        \n",
        "        class generator(Sequence):\n",
        "          \n",
        "          def __len__(_self):\n",
        "              return self.length\n",
        "          \n",
        "          def __getitem__(_self, index):\n",
        "              return cache_file['x/{}'.format(index % (counter['i'] if not counter['full'] else batch_pool))].value.astype('float')\n",
        "                \n",
        "        enqueuer = OrderedEnqueuer(\n",
        "                      generator(),\n",
        "                      use_multiprocessing=False,\n",
        "                      shuffle=False)\n",
        "        enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n",
        "        self.o_g = enqueuer.get()\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idx = -1\n",
        "        return self\n",
        "      \n",
        "    def __next__(self):\n",
        "        self.idx += 1\n",
        "        if self.idx >= self.length:\n",
        "            raise StopIteration()\n",
        "        return next(self.o_g)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return self.length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIQn0pnWfvoj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ]
    },
    {
      "metadata": {
        "id": "psbNazmKfpFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.python.keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "os.makedirs('data/bedroom', exist_ok=True)\n",
        "\n",
        "data_use = 'mnist' #@param [\"bedroom\", \"mnist\"] {allow-input: false}\n",
        "if data_use=='mnist':\n",
        "    img_rows = 28\n",
        "    img_cols = 28\n",
        "    channels = 1\n",
        "else:\n",
        "    img_rows = 64\n",
        "    img_cols = 64\n",
        "    channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 100\n",
        "batch_size = 64\n",
        "sample_interval = 200\n",
        "epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6j3-fn2VJ2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "from google.colab import files\n",
        "if data_use == 'bedroom':\n",
        "    print('Please upload your kaggle api json.')\n",
        "    files.upload()\n",
        "\n",
        "    ! mkdir /root/.kaggle\n",
        "    ! mv ./kaggle.json /root/.kaggle\n",
        "    ! chmod 600 /root/.kaggle/kaggle.json\n",
        "    ! kaggle datasets download -d jhoward/lsun_bedroom\n",
        "\n",
        "    out_fname = 'lsun_bedroom.zip'\n",
        "    zip_ref = zipfile.ZipFile(out_fname)\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "    os.remove(out_fname)\n",
        "\n",
        "    out_fname = 'sample.zip'\n",
        "    zip_ref = zipfile.ZipFile(out_fname)\n",
        "    zip_ref.extractall('data/bedroom/')\n",
        "    zip_ref.close()\n",
        "    os.remove(out_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDkhsw7vMBNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UpSample on TPU\n",
        "from tensorflow.python.keras.engine.base_layer import InputSpec\n",
        "from tensorflow.python.keras.utils import get_custom_objects\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "\n",
        "def _blur2d(x, f=[1,2,1], normalize=True, flip=False, stride=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(stride, int) and stride >= 1\n",
        "\n",
        "    # Finalize filter kernel.\n",
        "    f = np.array(f, dtype=np.float32)\n",
        "    if f.ndim == 1:\n",
        "        f = f[:, np.newaxis] * f[np.newaxis, :]\n",
        "    assert f.ndim == 2\n",
        "    if normalize:\n",
        "        f /= np.sum(f)\n",
        "    if flip:\n",
        "        f = f[::-1, ::-1]\n",
        "    f = f[:, :, np.newaxis, np.newaxis]\n",
        "    f = np.tile(f, [1, 1, int(x.shape[1]), 1])\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if f.shape == (1, 1) and f[0,0] == 1:\n",
        "        return x\n",
        "\n",
        "    # Convolve using depthwise_conv2d.\n",
        "    orig_dtype = x.dtype\n",
        "    x = tf.cast(x, tf.float32)  # tf.nn.depthwise_conv2d() doesn't support fp16\n",
        "    f = tf.constant(f, dtype=x.dtype, name='filter')\n",
        "    strides = [1, 1, stride, stride]\n",
        "    x = tf.nn.depthwise_conv2d(x, f, strides=strides, padding='SAME', data_format='NCHW')\n",
        "    x = tf.cast(x, orig_dtype)\n",
        "    return x\n",
        "\n",
        "def _upscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Upscale using tf.tile().\n",
        "    s = x.shape\n",
        "    x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "    x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "    x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x\n",
        "\n",
        "def _downscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # 2x2, float32 => downscale using _blur2d().\n",
        "    if factor == 2 and x.dtype == tf.float32:\n",
        "        f = [np.sqrt(gain) / factor] * factor\n",
        "        return _blur2d(x, f=f, normalize=False, stride=factor)\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Large factor => downscale using tf.nn.avg_pool().\n",
        "    # NOTE: Requires tf_config['graph_options.place_pruned_graph']=True to work.\n",
        "    ksize = [1, 1, factor, factor]\n",
        "    return tf.nn.avg_pool(x, ksize=ksize, strides=ksize, padding='VALID', data_format='NCHW')\n",
        "  \n",
        "def upscale2d(x, factor=2):\n",
        "    with tf.variable_scope('Upscale2D'):\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = _upscale2d(x, factor)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = _downscale2d(dy, factor, gain=factor**2)\n",
        "                return dx, lambda ddx: _upscale2d(ddx, factor)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "      \n",
        "class UpSampling2D(keras.layers.Layer):\n",
        "  \"\"\"Upsampling layer for 2D inputs.\n",
        "  Repeats the rows and columns of the data\n",
        "  by size[0] and size[1] respectively.\n",
        "  Arguments:\n",
        "      size: int, or tuple of 2 integers.\n",
        "          The upsampling factors for rows and columns.\n",
        "      data_format: A string,\n",
        "          one of `channels_last` (default) or `channels_first`.\n",
        "          The ordering of the dimensions in the inputs.\n",
        "          `channels_last` corresponds to inputs with shape\n",
        "          `(batch, height, width, channels)` while `channels_first`\n",
        "          corresponds to inputs with shape\n",
        "          `(batch, channels, height, width)`.\n",
        "          It defaults to the `image_data_format` value found in your\n",
        "          Keras config file at `~/.keras/keras.json`.\n",
        "          If you never set it, then it will be \"channels_last\".\n",
        "  Input shape:\n",
        "      4D tensor with shape:\n",
        "      - If `data_format` is `\"channels_last\"`:\n",
        "          `(batch, rows, cols, channels)`\n",
        "      - If `data_format` is `\"channels_first\"`:\n",
        "          `(batch, channels, rows, cols)`\n",
        "  Output shape:\n",
        "      4D tensor with shape:\n",
        "      - If `data_format` is `\"channels_last\"`:\n",
        "          `(batch, upsampled_rows, upsampled_cols, channels)`\n",
        "      - If `data_format` is `\"channels_first\"`:\n",
        "          `(batch, channels, upsampled_rows, upsampled_cols)`\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
        "    super(UpSampling2D, self).__init__(**kwargs)\n",
        "    self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "    self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
        "    self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.data_format == 'channels_first':\n",
        "      return upscale2d(inputs, self.size[0])\n",
        "    else:\n",
        "      T = tf.transpose(inputs, [0,3,1,2])\n",
        "      up_T = upscale2d(T, self.size[0])\n",
        "      return tf.transpose(up_T, [0,2,3,1])\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'size': self.size, 'data_format': self.data_format}\n",
        "    base_config = super(UpSampling2D, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "    \n",
        "get_custom_objects().update({'UpSampling2D': UpSampling2D})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjDp0s5ZgqlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "  \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        model = self.layers\n",
        "        model.append(Dense(128 * img_rows * img_cols // (4**2), activation=\"relu\", input_dim=latent_dim))\n",
        "        model.append(Reshape((img_rows//4, img_cols//4, 128)))\n",
        "        model.append(UpSampling2D())\n",
        "        model.append(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(Activation(\"relu\"))\n",
        "        model.append(UpSampling2D())\n",
        "        model.append(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(Activation(\"relu\"))\n",
        "        model.append(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
        "        model.append(Activation(\"tanh\", name='output'))\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        y = x\n",
        "        for layer in self.layers:\n",
        "            y = layer(y)\n",
        "        \n",
        "        return y\n",
        "\n",
        "class Discriminator:\n",
        "  \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        model = self.layers\n",
        "        model.append(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.append(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Flatten())\n",
        "        model.append(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y = x\n",
        "        for layer in self.layers:\n",
        "            y = layer(y)\n",
        "            \n",
        "        return y\n",
        "  \n",
        "def SelfGAN():\n",
        "    \n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "    \n",
        "    real_img = Input(shape=img_shape)\n",
        "    fake_img = Input(shape=img_shape)\n",
        "    \n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    gen_img = generator(noise)\n",
        "    validity_gen = discriminator(gen_img)\n",
        "    validity_real = discriminator(real_img)\n",
        "    validity_fake = discriminator(fake_img)\n",
        "    \n",
        "    # compute loss\n",
        "    adversarial_loss = Lambda(lambda x: keras.losses.binary_crossentropy(x[0], x[1]))\n",
        "    \n",
        "    \n",
        "    valid = Input(shape=(1,))\n",
        "    fake = Input(shape=(1,))\n",
        "    gen_loss = adversarial_loss([validity_gen, valid])\n",
        "    real_loss = adversarial_loss([validity_real, valid])\n",
        "    fake_loss = adversarial_loss([validity_fake, fake])\n",
        "    gen_loss = Lambda(lambda x: x*1.0, name='gen_loss')(gen_loss)\n",
        "    real_loss = Lambda(lambda x: x*1.0, name='real_loss')(real_loss)\n",
        "    fake_loss = Lambda(lambda x: x*1.0, name='fake_loss')(fake_loss)\n",
        "    \n",
        "    v_g = Lambda(lambda x: 1 - K.mean(x))(validity_gen)\n",
        "    v_r = Lambda(lambda x: 1 - K.mean(x))(validity_real)\n",
        "    v_f = Lambda(lambda x: K.mean(x))(validity_fake)\n",
        "    v_sum = Lambda(lambda x: x[0]+x[1]+x[2])([v_g,v_r,v_f])\n",
        "    s_loss = Lambda(lambda x: x[2]*x[1]/x[0] \\\n",
        "                            + x[4]*x[3]/x[0] \\\n",
        "                            + x[6]*x[5]/x[0])([v_sum, v_r, real_loss, v_g, gen_loss, v_f, fake_loss])\n",
        "    \n",
        "    return Model([noise, real_img, fake_img, valid, fake], [s_loss])\n",
        "  \n",
        "def sample_images(model, epoch):\n",
        "    r = 5\n",
        "    c = 5\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = model.predict([noise, last_imgs, last_imgs, valid, fake])[-1][:r*c]\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            if channels==1:\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            else:\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lipEQUtOX_UA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function override\n",
        "from tensorflow.contrib.tpu.python.tpu.keras_support import TPUFunction\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.estimator import model_fn as model_fn_lib \n",
        "ModeKeys = model_fn_lib.ModeKeys\n",
        "\n",
        "def extra_outputs(self):\n",
        "  outputs = []\n",
        "  for layer in self.layers:\n",
        "    if 'loss' in layer.name:\n",
        "      outputs.append(layer.output)\n",
        "  for layer in self.layers:\n",
        "    if 'output' in layer.name:\n",
        "      outputs.append(layer.output)\n",
        "  return outputs\n",
        "\n",
        "def _make_predict_function(self):\n",
        "  if not hasattr(self, 'predict_function'):\n",
        "    self.predict_function = None\n",
        "  if self.predict_function is None:\n",
        "    inputs = self._feed_inputs\n",
        "    # Gets network outputs. Does not update weights.\n",
        "    # Does update the network states.\n",
        "    kwargs = getattr(self, '_function_kwargs', {})\n",
        "    with K.name_scope(ModeKeys.PREDICT):\n",
        "      self.predict_function = K.function(\n",
        "          inputs,\n",
        "          self.outputs+extra_outputs(self),\n",
        "          updates=self.state_updates,\n",
        "          name='predict_function',\n",
        "          **kwargs)\n",
        "      \n",
        "def _make_fit_function(self):\n",
        "  metrics_tensors = [\n",
        "      self._all_stateful_metrics_tensors[m] for m in self.metrics_names[1:]\n",
        "  ]\n",
        "  self._make_train_function_helper(\n",
        "      '_fit_function', [self.total_loss] + metrics_tensors + extra_outputs(self))\n",
        "  \n",
        "Model._make_predict_function = _make_predict_function\n",
        "Model._make_fit_function = _make_fit_function\n",
        "\n",
        "def _process_outputs(self, outfeed_outputs):\n",
        "    \"\"\"Processes the outputs of a model function execution.\n",
        "    Args:\n",
        "      outfeed_outputs: The sharded outputs of the TPU computation.\n",
        "    Returns:\n",
        "      The aggregated outputs of the TPU computation to be used in the rest of\n",
        "      the model execution.\n",
        "    \"\"\"\n",
        "    # TODO(xiejw): Decide how to reduce outputs, or discard all but first.\n",
        "    if self.execution_mode == ModeKeys.PREDICT:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "\n",
        "      return [np.concatenate(group) for group in outputs]\n",
        "    else:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "      \n",
        "      ret = []\n",
        "      for group in outputs:\n",
        "        if len(group[0].shape) > 0:\n",
        "          ret.append(np.concatenate(group))\n",
        "        else:\n",
        "          ret.append(group[0])\n",
        "      return ret\n",
        "    \n",
        "TPUFunction._process_outputs = _process_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8kXVRyfpz2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "model = SelfGAN()\n",
        "model.compile(loss='mae',optimizer=optimizer)\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "def initialize_uninitialized_variables():\n",
        "    sess = K.get_session()\n",
        "    uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "    init_op = tf.variables_initializer(\n",
        "        [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        "    )\n",
        "    sess.run(init_op)\n",
        "initialize_uninitialized_variables()\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "last_imgs = np.zeros((batch_size,)+img_shape)\n",
        "s_loss_zeros = np.zeros((batch_size,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly2F41ptrog1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Init tpu model\n",
        "noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "train_outputs = model.train_on_batch([noise, last_imgs, last_imgs, valid, fake], [s_loss_zeros])\n",
        "predict_output = model.predict([noise, last_imgs, last_imgs, valid, fake])\n",
        "\n",
        "dataLoader = DataLoader(ImageDataset('data/bedroom') if data_use == 'bedroom' else \n",
        "                            mnist.load_data()[0][0].reshape((-1,28,28,1))/127.5-1, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVjnI8dKspOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  \n",
        "    for i, imgs in enumerate(dataLoader):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        \n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Generate a batch of new images\n",
        "\n",
        "        outputs = model.train_on_batch([noise, imgs, last_imgs, valid, fake], [s_loss_zeros])\n",
        "        s_loss = outputs[0]/8\n",
        "        gen_loss = np.mean(outputs[2])/(batch_size/8)\n",
        "        real_loss = np.mean(outputs[1])/(batch_size/8)\n",
        "        fake_loss = np.mean(outputs[3])/(batch_size/8)\n",
        "        last_imgs = outputs[-1]\n",
        "\n",
        "        # Plot the progress\n",
        "        if i % 25 == 0:\n",
        "            sys.stdout.flush()\n",
        "            print (\"\\r[Epoch %d/%d] [Batch %d/%d]  [S loss: %f  G loss: %f R loss: %f  F loss: %f]\" % (epoch, epochs, i,\n",
        "                                                                            len(dataLoader), s_loss,\n",
        "                                                                            gen_loss, real_loss, fake_loss),end='')\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if (epoch*len(dataLoader) + i) % sample_interval == 0:\n",
        "            sample_images(model, epoch*len(dataLoader) + i)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}