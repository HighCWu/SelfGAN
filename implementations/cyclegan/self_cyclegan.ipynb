{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_cyclegan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "gZd0PC8ddn6a"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qXRAKEQFaPy8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Self CycleGAN\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/HighCWu/SelfGAN/blob/master/implementations/cyclegan/self_cyclegan.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/HighCWu/SelfGAN/blob/master/implementations/cyclegan/self_cyclegan.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "vUE9-JNtSopo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ]
    },
    {
      "metadata": {
        "id": "0lTbFidRSk2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))\n",
        "\n",
        "class LambdaLR():\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vRxN8cQBggjp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ]
    },
    {
      "metadata": {
        "id": "-2NtBKi4gkEI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, '%sA' % mode) + '/*.*'))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, '%sB' % mode) + '/*.*'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
        "\n",
        "        if self.unaligned:\n",
        "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]).convert('RGB'))\n",
        "        else:\n",
        "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]).convert('RGB'))\n",
        "\n",
        "        return {'A': item_A, 'B': item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xe-19JNagnO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "e6JpPGDRhBEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "##############################\n",
        "#           RESNET\n",
        "##############################\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features)  ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, res_blocks=9):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        # Initial convolution block\n",
        "        model = [   nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(in_channels, 64, 7),\n",
        "                    nn.InstanceNorm2d(64),\n",
        "                    nn.ReLU(inplace=True) ]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = 64\n",
        "        out_features = in_features*2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features*2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(res_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features//2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features//2\n",
        "\n",
        "        # Output layer\n",
        "        model += [  nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(64, out_channels, 7),\n",
        "                    nn.Tanh() ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "##############################\n",
        "#        Discriminator\n",
        "##############################\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "\n",
        "##############################\n",
        "#        Self CycleGAN\n",
        "##############################\n",
        "\n",
        "class SelfCycleGAN(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, res_blocks=9):\n",
        "        super(SelfCycleGAN, self).__init__()\n",
        "\n",
        "        # Initialize generator and discriminator\n",
        "        self.G_AB = GeneratorResNet(in_channels, out_channels, res_blocks)\n",
        "        self.G_BA = GeneratorResNet(in_channels, out_channels, res_blocks)\n",
        "        self.D_A = Discriminator(in_channels)\n",
        "        self.D_B = Discriminator(in_channels)\n",
        "        \n",
        "    def forward(self, realA, realB, fakeA, fakeB):\n",
        "        # Identity gen\n",
        "        idenA = self.G_BA(realA)\n",
        "        idenB = self.G_AB(realB)\n",
        "        \n",
        "        # GAN validity\n",
        "        genA = self.G_BA(realB)\n",
        "        genB = self.G_AB(realA)\n",
        "        validity_genA = self.D_A(genA)\n",
        "        validity_realA = self.D_A(realA)\n",
        "        validity_fakeA = self.D_A(fakeA)\n",
        "        validity_genB = self.D_B(genB)\n",
        "        validity_realB = self.D_B(realB)\n",
        "        validity_fakeB = self.D_B(fakeB)\n",
        "        \n",
        "        # Cycle gen\n",
        "        recA = self.G_BA(genB)\n",
        "        recB = self.G_AB(genA)\n",
        "\n",
        "        return idenA, idenB, \\\n",
        "               genA, genB, \\\n",
        "               validity_genA, validity_realA, validity_fakeA, \\\n",
        "               validity_genB, validity_realB, validity_fakeB, \\\n",
        "               recA, recB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKiW6WoRcHGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ]
    },
    {
      "metadata": {
        "id": "iv57iXGFL1iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--epoch', type=int, default=0, help='epoch to start training from')\n",
        "parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')\n",
        "parser.add_argument('--dataset_name', type=str, default=\"horse2zebra\", help='name of the dataset')\n",
        "parser.add_argument('--batch_size', type=int, default=1, help='size of the batches')\n",
        "parser.add_argument('--lr', type=float, default=0.0002, help='adam: learning rate')\n",
        "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
        "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
        "parser.add_argument('--decay_epoch', type=int, default=100, help='epoch from which to start lr decay')\n",
        "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
        "parser.add_argument('--img_height', type=int, default=128, help='size of image height')\n",
        "parser.add_argument('--img_width', type=int, default=128, help='size of image width')\n",
        "parser.add_argument('--channels', type=int, default=3, help='number of image channels')\n",
        "parser.add_argument('--sample_interval', type=int, default=100, help='interval between sampling images from generators')\n",
        "parser.add_argument('--checkpoint_interval', type=int, default=-1, help='interval between saving model checkpoints')\n",
        "parser.add_argument('--n_residual_blocks', type=int, default=9, help='number of residual blocks in generator')\n",
        "\n",
        "opt,_ = parser.parse_known_args()\n",
        "print(opt)\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('images/%s' % opt.dataset_name, exist_ok=True)\n",
        "os.makedirs('images_normal/%s' % opt.dataset_name, exist_ok=True)\n",
        "os.makedirs('saved_models/%s' % opt.dataset_name, exist_ok=True)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7af-qbvAp3Ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install wget -q\n",
        "import wget, zipfile\n",
        "import os\n",
        "\n",
        "dataset_url = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{}.zip'.format(opt.dataset_name)\n",
        "out_fname = '{}.zip'.format(opt.dataset_name)\n",
        "wget.download(dataset_url, out=out_fname)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(out_fname)\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()\n",
        "\n",
        "os.remove(out_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iiRxa6X0df0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SelfGAN Part"
      ]
    },
    {
      "metadata": {
        "id": "2HjdTESzahT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Losses\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (1, opt.img_height // 2**4, opt.img_width // 2**4)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "self_cycle = SelfCycleGAN(res_blocks=opt.n_residual_blocks)\n",
        "\n",
        "if cuda:\n",
        "    self_cycle = self_cycle.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()\n",
        "\n",
        "if opt.epoch != 0:\n",
        "    # Load pretrained models\n",
        "    self_cycle.load_state_dict(torch.load('saved_models/%s/self_cycle_%d.pth' % (opt.dataset_name, opt.epoch)))\n",
        "else:\n",
        "    # Initialize weights\n",
        "    self_cycle.apply(weights_init_normal)\n",
        "\n",
        "# Loss weights\n",
        "lambda_cyc = 10\n",
        "lambda_id = 0.5 * lambda_cyc\n",
        "\n",
        "# Optimizers\n",
        "optimizer = torch.optim.Adam(self_cycle.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "# Learning rate update schedulers\n",
        "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "# Buffers of previously generated samples\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# Image transformations\n",
        "transforms_ = [ transforms.Resize(int(opt.img_height*1.12), Image.BICUBIC),\n",
        "                transforms.RandomCrop((opt.img_height, opt.img_width)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "\n",
        "# Training data loader\n",
        "dataloader = DataLoader(ImageDataset(\"data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True),\n",
        "                        batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu, drop_last=True)\n",
        "# Test data loader\n",
        "val_dataloader = DataLoader(ImageDataset(\"data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True, mode='test'),\n",
        "                        batch_size=5, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    real_A = Variable(imgs['A'].type(Tensor))\n",
        "    fake_B = self_cycle.G_AB(real_A)\n",
        "    real_B = Variable(imgs['B'].type(Tensor))\n",
        "    fake_A = self_cycle.G_BA(real_B)\n",
        "    img_sample = torch.cat((real_A.data, fake_B.data,\n",
        "                            real_B.data, fake_A.data), 0)\n",
        "    save_image(img_sample, 'images/%s/%s.png' % (opt.dataset_name, batches_done), nrow=5, normalize=True)\n",
        "    \n",
        "fake_A_ = fake_A_buffer.push_and_pop(Tensor(opt.batch_size, opt.channels, opt.img_height, opt.img_width)*0.0)\n",
        "fake_B_ = fake_B_buffer.push_and_pop(Tensor(opt.batch_size, opt.channels, opt.img_height, opt.img_width)*0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ytnn34ySdJvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "prev_time = time.time()\n",
        "for epoch in range(opt.epoch, opt.n_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Set model input\n",
        "        real_A = Variable(batch['A'].type(Tensor))\n",
        "        real_B = Variable(batch['B'].type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        idenA, idenB, \\\n",
        "        genA, genB, \\\n",
        "        validity_genA, validity_realA, validity_fakeA, \\\n",
        "        validity_genB, validity_realB, validity_fakeB, \\\n",
        "        recA, recB = self_cycle(real_A, real_B, fake_A_, fake_B_)\n",
        "\n",
        "        # Identity loss\n",
        "        loss_id_A = criterion_identity(idenA, real_A)\n",
        "        loss_id_B = criterion_identity(idenB, real_B)\n",
        "\n",
        "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
        "\n",
        "        # Self GAN loss\n",
        "        genA_loss = criterion_GAN(validity_genA, valid)\n",
        "        realA_loss = criterion_GAN(validity_realA, valid)\n",
        "        fakeA_loss = criterion_GAN(validity_fakeA, fake)\n",
        "        v_g = torch.abs(torch.mean(validity_genA) - 1)\n",
        "        v_f = torch.abs(torch.mean(validity_fakeA) - 0)\n",
        "        r_g = (v_g / (v_g + v_f)).detach()\n",
        "        loss_s_A = (realA_loss + v_g*genA_loss*0.1 + v_f*fakeA_loss*0.9) / 2\n",
        "        genB_loss = criterion_GAN(validity_genB, valid)\n",
        "        realB_loss = criterion_GAN(validity_realB, valid)\n",
        "        fakeB_loss = criterion_GAN(validity_fakeB, fake)\n",
        "        v_g = torch.abs(torch.mean(validity_genB) - 1)\n",
        "        v_f = torch.abs(torch.mean(validity_fakeB) - 0)\n",
        "        r_g = (v_g / (v_g + v_f)).detach()\n",
        "        loss_s_B = (realB_loss + v_g*genB_loss*0.1 + v_f*fakeB_loss*0.9) / 2\n",
        "\n",
        "        loss_s = (loss_s_A + loss_s_B) / 2\n",
        "\n",
        "        # Cycle loss\n",
        "        loss_cycle_A = criterion_cycle(recA, real_A)\n",
        "        loss_cycle_B = criterion_cycle(recB, real_B)\n",
        "\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "        # Total loss\n",
        "        loss_All =  loss_s + \\\n",
        "                    lambda_cyc * loss_cycle + \\\n",
        "                    lambda_id * loss_identity\n",
        "\n",
        "        loss_All.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        fake_A_ = fake_A_buffer.push_and_pop(genA.detach())\n",
        "        fake_B_ = fake_A_buffer.push_and_pop(genB.detach())\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        # Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "        # Print log\n",
        "        sys.stdout.write(\"\\r[Epoch %d/%d] [Batch %d/%d] [All loss: %f, self: %f, cycle: %f, identity: %f] ETA: %s\" %\n",
        "                                                        (epoch, opt.n_epochs,\n",
        "                                                        i, len(dataloader),\n",
        "                                                        loss_All.item(),\n",
        "                                                        loss_s.item(), loss_cycle.item(),\n",
        "                                                        loss_identity.item(), time_left))\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "\n",
        "\n",
        "    # Update learning rates\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "        # Save model checkpoints\n",
        "        torch.save(self_cycle.state_dict(), 'saved_models/%s/self_cycle_%d.pth' % (opt.dataset_name, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZd0PC8ddn6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normal GAN Part"
      ]
    },
    {
      "metadata": {
        "id": "dv8ovPfrdsaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Losses\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "# Calculate output of image discriminator (PatchGAN)\n",
        "patch = (1, opt.img_height // 2**4, opt.img_width // 2**4)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "G_AB = GeneratorResNet(res_blocks=opt.n_residual_blocks)\n",
        "G_BA = GeneratorResNet(res_blocks=opt.n_residual_blocks)\n",
        "D_A = Discriminator()\n",
        "D_B = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    G_AB = G_AB.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()\n",
        "\n",
        "if opt.epoch != 0:\n",
        "    # Load pretrained models\n",
        "    G_AB.load_state_dict(torch.load('saved_models/%s/G_AB_%d.pth' % (opt.dataset_name, opt.epoch)))\n",
        "    G_BA.load_state_dict(torch.load('saved_models/%s/G_BA_%d.pth' % (opt.dataset_name, opt.epoch)))\n",
        "    D_A.load_state_dict(torch.load('saved_models/%s/D_A_%d.pth' % (opt.dataset_name, opt.epoch)))\n",
        "    D_B.load_state_dict(torch.load('saved_models/%s/D_B_%d.pth' % (opt.dataset_name, opt.epoch)))\n",
        "else:\n",
        "    # Initialize weights\n",
        "    G_AB.apply(weights_init_normal)\n",
        "    G_BA.apply(weights_init_normal)\n",
        "    D_A.apply(weights_init_normal)\n",
        "    D_B.apply(weights_init_normal)\n",
        "\n",
        "# Loss weights\n",
        "lambda_cyc = 10\n",
        "lambda_id = 0.5 * lambda_cyc\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
        "                                lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "# Learning rate update schedulers\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "# Buffers of previously generated samples\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# Image transformations\n",
        "transforms_ = [ transforms.Resize(int(opt.img_height*1.12), Image.BICUBIC),\n",
        "                transforms.RandomCrop((opt.img_height, opt.img_width)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "\n",
        "# Training data loader\n",
        "dataloader = DataLoader(ImageDataset(\"data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True),\n",
        "                        batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n",
        "# Test data loader\n",
        "val_dataloader = DataLoader(ImageDataset(\"data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True, mode='test'),\n",
        "                        batch_size=5, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    real_A = Variable(imgs['A'].type(Tensor))\n",
        "    fake_B = G_AB(real_A)\n",
        "    real_B = Variable(imgs['B'].type(Tensor))\n",
        "    fake_A = G_BA(real_B)\n",
        "    img_sample = torch.cat((real_A.data, fake_B.data,\n",
        "                            real_B.data, fake_A.data), 0)\n",
        "    save_image(img_sample, 'images_normal/%s/%s.png' % (opt.dataset_name, batches_done), nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlmNSQ2Odykq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "prev_time = time.time()\n",
        "for epoch in range(opt.epoch, opt.n_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Set model input\n",
        "        real_A = Variable(batch['A'].type(Tensor))\n",
        "        real_B = Variable(batch['B'].type(Tensor))\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity loss\n",
        "        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n",
        "        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n",
        "\n",
        "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = G_AB(real_A)\n",
        "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n",
        "        fake_A = G_BA(real_B)\n",
        "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n",
        "\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "        # Cycle loss\n",
        "        recov_A = G_BA(fake_B)\n",
        "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
        "        recov_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
        "\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "        # Total loss\n",
        "        loss_G =    loss_GAN + \\\n",
        "                    lambda_cyc * loss_cycle + \\\n",
        "                    lambda_id * loss_identity\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator A\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        loss_real = criterion_GAN(D_A(real_A), valid)\n",
        "        # Fake loss (on batch of previously generated samples)\n",
        "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
        "        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
        "        # Total loss\n",
        "        loss_D_A = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # -----------------------\n",
        "        #  Train Discriminator B\n",
        "        # -----------------------\n",
        "\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        loss_real = criterion_GAN(D_B(real_B), valid)\n",
        "        # Fake loss (on batch of previously generated samples)\n",
        "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
        "        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n",
        "        # Total loss\n",
        "        loss_D_B = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        loss_D = (loss_D_A + loss_D_B) / 2\n",
        "\n",
        "        # --------------\n",
        "        #  Log Progress\n",
        "        # --------------\n",
        "\n",
        "        # Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = opt.n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "        # Print log\n",
        "        sys.stdout.write(\"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\" %\n",
        "                                                        (epoch, opt.n_epochs,\n",
        "                                                        i, len(dataloader),\n",
        "                                                        loss_D.item(), loss_G.item(),\n",
        "                                                        loss_GAN.item(), loss_cycle.item(),\n",
        "                                                        loss_identity.item(), time_left))\n",
        "\n",
        "        # If at sample interval save image\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "\n",
        "\n",
        "    # Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "\n",
        "    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "        # Save model checkpoints\n",
        "        torch.save(G_AB.state_dict(), 'saved_models/%s/G_AB_%d.pth' % (opt.dataset_name, epoch))\n",
        "        torch.save(G_BA.state_dict(), 'saved_models/%s/G_BA_%d.pth' % (opt.dataset_name, epoch))\n",
        "        torch.save(D_A.state_dict(), 'saved_models/%s/D_A_%d.pth' % (opt.dataset_name, epoch))\n",
        "        torch.save(D_B.state_dict(), 'saved_models/%s/D_B_%d.pth' % (opt.dataset_name, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}