{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_cyclegan_keras_tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mUaJMUDUezt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Self CycleGAN Keras TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/HighCWu/SelfGAN/blob/master/implementations/cyclegan/self_cyclegan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/HighCWu/SelfGAN/blob/master/implementations/cyclegan/self_cyclegan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "_sFEKpmpesjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install 'tensorflow>1.12,<2.0' -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vISGhDaKyOTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ]
    },
    {
      "metadata": {
        "id": "8otfPNtPyQvS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        \n",
        "        if len(self.data) < self.max_size:\n",
        "            ret = data\n",
        "            self.data.append(data)\n",
        "        else:\n",
        "            ret = self.data.pop(0)\n",
        "            self.data.append(data)\n",
        "        return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHK5Y87sVWAa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ]
    },
    {
      "metadata": {
        "id": "yg6TxwMvVVKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import threading\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.python.keras.utils import Sequence\n",
        "from tensorflow.python.keras.utils.data_utils import OrderedEnqueuer\n",
        "\n",
        "class ImageDataset:\n",
        "  \n",
        "    def __init__(self, root):\n",
        "\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, '%sA' % 'train') + '/*.*'))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, '%sB' % 'train') + '/*.*'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.open(self.files_A[index % len(self.files_A)]).convert('RGB' if channels==3 else 'L')\n",
        "        w, h = img.size\n",
        "        img = img.resize((img_rows, img_cols), Image.LANCZOS)\n",
        "        img = np.asarray(img)\n",
        "        img = img/255*2 - 1\n",
        "        if channels==1:\n",
        "            img = img.reshape(img.shape+(1,))\n",
        "        imgA = img    \n",
        "        \n",
        "            \n",
        "        img = Image.open(self.files_B[index % len(self.files_B)]).convert('RGB' if channels==3 else 'L')\n",
        "        w, h = img.size\n",
        "        img = img.resize((img_rows, img_cols), Image.LANCZOS)\n",
        "        img = np.asarray(img)\n",
        "        img = img/255*2 - 1\n",
        "        if channels==1:\n",
        "            img = img.reshape(img.shape+(1,))\n",
        "        imgB = img\n",
        "\n",
        "        return imgA, imgB\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "      \n",
        "class DataLoader:\n",
        "    \n",
        "    def __init__(self, dataset, batch_size, workers=1, max_queue_size=10, cache_filepath='tmp/cache.h5', pool_size=8000):\n",
        "        self.idx = 0\n",
        "        bsz = batch_size\n",
        "        batch_pool = pool_size // bsz\n",
        "        self.length = batch_pool\n",
        "        \n",
        "        os.makedirs(os.path.dirname(cache_filepath), exist_ok=True)\n",
        "        cache_file = h5py.File(cache_filepath, 'w')\n",
        "        counter = {'i': 0, 'full': False}\n",
        "        def data_reader(counter, cache_file):\n",
        "          idx = 0\n",
        "          while True:\n",
        "            try:\n",
        "              X=[]\n",
        "              Y=[]\n",
        "              for i in range(bsz):\n",
        "                x,y = dataset[idx]\n",
        "                X.append(x)\n",
        "                Y.append(y)\n",
        "                idx = (idx + 1) % len(dataset)\n",
        "\n",
        "              if not counter['full']:\n",
        "                cache_file.create_dataset('x/{}'.format(counter['i']), data=X)\n",
        "                cache_file.create_dataset('y/{}'.format(counter['i']), data=Y)\n",
        "              else:\n",
        "                cache_file['x/{}'.format(counter['i'])][...] = X\n",
        "                cache_file['y/{}'.format(counter['i'])][...] = Y\n",
        "              counter['i'] = (counter['i']+1)%(batch_pool)\n",
        "              if counter['i'] == 0:\n",
        "                counter['full'] = True\n",
        "              time.sleep(0.5)\n",
        "            except Exception as e:\n",
        "              raise e\n",
        "\n",
        "        dt = threading.Thread(target=data_reader, args=(counter, cache_file))\n",
        "        dt.start()\n",
        "        while counter['i'] < 100:\n",
        "          sys.stdout.flush()\n",
        "          if counter['i']%25==0:\n",
        "            print('\\rWaiting for enough cache.%d/100'%counter['i'], end='')\n",
        "        print('')\n",
        "        \n",
        "        class generator(Sequence):\n",
        "          \n",
        "          def __len__(_self):\n",
        "              return self.length\n",
        "          \n",
        "          def __getitem__(_self, index):\n",
        "              return cache_file['x/{}'.format(index % (counter['i'] if not counter['full'] else batch_pool))].value.astype('float'), \\\n",
        "                     cache_file['y/{}'.format(index % (counter['i'] if not counter['full'] else batch_pool))].value.astype('float')\n",
        "                \n",
        "        enqueuer = OrderedEnqueuer(\n",
        "                      generator(),\n",
        "                      use_multiprocessing=False,\n",
        "                      shuffle=False)\n",
        "        enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n",
        "        self.o_g = enqueuer.get()\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idx = -1\n",
        "        return self\n",
        "      \n",
        "    def __next__(self):\n",
        "        self.idx += 1\n",
        "        if self.idx >= self.length:\n",
        "            raise StopIteration()\n",
        "        return next(self.o_g)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return self.length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIQn0pnWfvoj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ]
    },
    {
      "metadata": {
        "id": "psbNazmKfpFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.python.keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "img_rows = 128\n",
        "img_cols = 128\n",
        "channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "batch_size = 16\n",
        "gf = 64\n",
        "df = 64\n",
        "sample_interval = 100\n",
        "epochs = 200\n",
        "lambda_cyc = 10\n",
        "lambda_id = lambda_cyc*0.1\n",
        "\n",
        "dataset_name = 'horse2zebra'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6j3-fn2VJ2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install wget -q\n",
        "import wget, zipfile\n",
        "import os\n",
        "\n",
        "dataset_url = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{}.zip'.format(dataset_name)\n",
        "out_fname = '{}.zip'.format(dataset_name)\n",
        "wget.download(dataset_url, out=out_fname)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(out_fname)\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()\n",
        "\n",
        "os.remove(out_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDkhsw7vMBNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UpSample on TPU\n",
        "from tensorflow.python.keras.utils import get_custom_objects\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def _blur2d(x, f=[1,2,1], normalize=True, flip=False, stride=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(stride, int) and stride >= 1\n",
        "\n",
        "    # Finalize filter kernel.\n",
        "    f = np.array(f, dtype=np.float32)\n",
        "    if f.ndim == 1:\n",
        "        f = f[:, np.newaxis] * f[np.newaxis, :]\n",
        "    assert f.ndim == 2\n",
        "    if normalize:\n",
        "        f /= np.sum(f)\n",
        "    if flip:\n",
        "        f = f[::-1, ::-1]\n",
        "    f = f[:, :, np.newaxis, np.newaxis]\n",
        "    f = np.tile(f, [1, 1, int(x.shape[1]), 1])\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if f.shape == (1, 1) and f[0,0] == 1:\n",
        "        return x\n",
        "\n",
        "    # Convolve using depthwise_conv2d.\n",
        "    orig_dtype = x.dtype\n",
        "    x = tf.cast(x, tf.float32)  # tf.nn.depthwise_conv2d() doesn't support fp16\n",
        "    f = tf.constant(f, dtype=x.dtype, name='filter')\n",
        "    strides = [1, 1, stride, stride]\n",
        "    x = tf.nn.depthwise_conv2d(x, f, strides=strides, padding='SAME', data_format='NCHW')\n",
        "    x = tf.cast(x, orig_dtype)\n",
        "    return x\n",
        "\n",
        "def _upscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Upscale using tf.tile().\n",
        "    s = x.shape\n",
        "    x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
        "    x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "    x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
        "    return x\n",
        "\n",
        "def _downscale2d(x, factor=2, gain=1):\n",
        "    assert x.shape.ndims == 4 and all(dim.value is not None for dim in x.shape[1:])\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # 2x2, float32 => downscale using _blur2d().\n",
        "    if factor == 2 and x.dtype == tf.float32:\n",
        "        f = [np.sqrt(gain) / factor] * factor\n",
        "        return _blur2d(x, f=f, normalize=False, stride=factor)\n",
        "\n",
        "    # Apply gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "\n",
        "    # No-op => early exit.\n",
        "    if factor == 1:\n",
        "        return x\n",
        "\n",
        "    # Large factor => downscale using tf.nn.avg_pool().\n",
        "    # NOTE: Requires tf_config['graph_options.place_pruned_graph']=True to work.\n",
        "    ksize = [1, 1, factor, factor]\n",
        "    return tf.nn.avg_pool(x, ksize=ksize, strides=ksize, padding='VALID', data_format='NCHW')\n",
        "  \n",
        "def upscale2d(x, factor=2):\n",
        "    with tf.variable_scope('Upscale2D'):\n",
        "        @tf.custom_gradient\n",
        "        def func(x):\n",
        "            y = _upscale2d(x, factor)\n",
        "            @tf.custom_gradient\n",
        "            def grad(dy):\n",
        "                dx = _downscale2d(dy, factor, gain=factor**2)\n",
        "                return dx, lambda ddx: _upscale2d(ddx, factor)\n",
        "            return y, grad\n",
        "        return func(x)\n",
        "      \n",
        "class UpSampling2D(keras.layers.Layer):\n",
        "  \"\"\"Upsampling layer for 2D inputs.\n",
        "  Repeats the rows and columns of the data\n",
        "  by size[0] and size[1] respectively.\n",
        "  Arguments:\n",
        "      size: int, or tuple of 2 integers.\n",
        "          The upsampling factors for rows and columns.\n",
        "      data_format: A string,\n",
        "          one of `channels_last` (default) or `channels_first`.\n",
        "          The ordering of the dimensions in the inputs.\n",
        "          `channels_last` corresponds to inputs with shape\n",
        "          `(batch, height, width, channels)` while `channels_first`\n",
        "          corresponds to inputs with shape\n",
        "          `(batch, channels, height, width)`.\n",
        "          It defaults to the `image_data_format` value found in your\n",
        "          Keras config file at `~/.keras/keras.json`.\n",
        "          If you never set it, then it will be \"channels_last\".\n",
        "  Input shape:\n",
        "      4D tensor with shape:\n",
        "      - If `data_format` is `\"channels_last\"`:\n",
        "          `(batch, rows, cols, channels)`\n",
        "      - If `data_format` is `\"channels_first\"`:\n",
        "          `(batch, channels, rows, cols)`\n",
        "  Output shape:\n",
        "      4D tensor with shape:\n",
        "      - If `data_format` is `\"channels_last\"`:\n",
        "          `(batch, upsampled_rows, upsampled_cols, channels)`\n",
        "      - If `data_format` is `\"channels_first\"`:\n",
        "          `(batch, channels, upsampled_rows, upsampled_cols)`\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
        "    super(UpSampling2D, self).__init__(**kwargs)\n",
        "    self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "    self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
        "    self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.data_format == 'channels_first':\n",
        "      return upscale2d(inputs, self.size[0])\n",
        "    else:\n",
        "      T = tf.transpose(inputs, [0,3,1,2])\n",
        "      up_T = upscale2d(T, self.size[0])\n",
        "      return tf.transpose(up_T, [0,2,3,1])\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'size': self.size, 'data_format': self.data_format}\n",
        "    base_config = super(UpSampling2D, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "    \n",
        "get_custom_objects().update({'UpSampling2D': UpSampling2D})\n",
        "\n",
        "class InstanceNormalization(Layer):\n",
        "    \"\"\"Instance normalization layer.\n",
        "    Normalize the activations of the previous layer at each step,\n",
        "    i.e. applies a transformation that maintains the mean activation\n",
        "    close to 0 and the activation standard deviation close to 1.\n",
        "    # Arguments\n",
        "        axis: Integer, the axis that should be normalized\n",
        "            (typically the features axis).\n",
        "            For instance, after a `Conv2D` layer with\n",
        "            `data_format=\"channels_first\"`,\n",
        "            set `axis=1` in `InstanceNormalization`.\n",
        "            Setting `axis=None` will normalize all values in each\n",
        "            instance of the batch.\n",
        "            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "            When the next layer is linear (also e.g. `nn.relu`),\n",
        "            this can be disabled since the scaling\n",
        "            will be done by the next layer.\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "    # Input shape\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a Sequential model.\n",
        "    # Output shape\n",
        "        Same shape as input.\n",
        "    # References\n",
        "        - [Layer Normalization](https://arxiv.org/abs/1607.06450)\n",
        "        - [Instance Normalization: The Missing Ingredient for Fast Stylization](\n",
        "        https://arxiv.org/abs/1607.08022)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 axis=None,\n",
        "                 epsilon=1e-3,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 beta_initializer='zeros',\n",
        "                 gamma_initializer='ones',\n",
        "                 beta_regularizer=None,\n",
        "                 gamma_regularizer=None,\n",
        "                 beta_constraint=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(InstanceNormalization, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.beta_initializer = initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        ndim = len(input_shape)\n",
        "        if self.axis == 0:\n",
        "            raise ValueError('Axis cannot be zero')\n",
        "\n",
        "        if (self.axis is not None) and (ndim == 2):\n",
        "            raise ValueError('Cannot specify axis for rank 1 tensor')\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=ndim)\n",
        "\n",
        "        if self.axis is None:\n",
        "            shape = (1,)\n",
        "        else:\n",
        "            shape = (input_shape[self.axis],)\n",
        "\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(shape=shape,\n",
        "                                         name='gamma',\n",
        "                                         initializer=self.gamma_initializer,\n",
        "                                         regularizer=self.gamma_regularizer,\n",
        "                                         constraint=self.gamma_constraint)\n",
        "        else:\n",
        "            self.gamma = None\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=shape,\n",
        "                                        name='beta',\n",
        "                                        initializer=self.beta_initializer,\n",
        "                                        regularizer=self.beta_regularizer,\n",
        "                                        constraint=self.beta_constraint)\n",
        "        else:\n",
        "            self.beta = None\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        reduction_axes = list(range(0, len(input_shape)))\n",
        "\n",
        "        if self.axis is not None:\n",
        "            del reduction_axes[self.axis]\n",
        "\n",
        "        del reduction_axes[0]\n",
        "\n",
        "        mean = K.mean(inputs, reduction_axes, keepdims=True)\n",
        "        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n",
        "        normed = (inputs - mean) / stddev\n",
        "\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        if self.axis is not None:\n",
        "            broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        if self.scale:\n",
        "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "            normed = normed * broadcast_gamma\n",
        "        if self.center:\n",
        "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "            normed = normed + broadcast_beta\n",
        "        return normed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'axis': self.axis,\n",
        "            'epsilon': self.epsilon,\n",
        "            'center': self.center,\n",
        "            'scale': self.scale,\n",
        "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
        "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
        "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
        "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
        "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
        "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
        "        }\n",
        "        base_config = super(InstanceNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "get_custom_objects().update({'InstanceNormalization': InstanceNormalization})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjDp0s5ZgqlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "    \"\"\"U-Net Generator\"\"\"\n",
        "    def __init__(self):\n",
        "      \n",
        "        def conv2d(layer_input, filters, f_size=4):\n",
        "            \"\"\"Layers used during downsampling\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            d = InstanceNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "            \"\"\"Layers used during upsampling\"\"\"\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "            if dropout_rate:\n",
        "                u = Dropout(dropout_rate)(u)\n",
        "            u = InstanceNormalization()(u)\n",
        "            u = Concatenate()([u, skip_input])\n",
        "            return u\n",
        "\n",
        "        # Image input\n",
        "        d0 = Input(shape=img_shape)\n",
        "\n",
        "        # Downsampling\n",
        "        d1 = conv2d(d0, gf)\n",
        "        d2 = conv2d(d1, gf*2)\n",
        "        d3 = conv2d(d2, gf*4)\n",
        "        d4 = conv2d(d3, gf*8)\n",
        "\n",
        "        # Upsampling\n",
        "        u1 = deconv2d(d4, d3, gf*4)\n",
        "        u2 = deconv2d(u1, d2, gf*2)\n",
        "        u3 = deconv2d(u2, d1, gf)\n",
        "\n",
        "        u4 = UpSampling2D(size=2)(u3)\n",
        "        output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "\n",
        "        self.model =  Model(d0, output_img)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        \n",
        "        layers = {}\n",
        "        layers[self.model.layers[0].name] = x\n",
        "        y = x\n",
        "        for layer in self.model.layers[1:]:\n",
        "          if isinstance(layer.input, list):\n",
        "            y = []\n",
        "            for inp in layer.input:\n",
        "              name = inp.name.split(':')[0].split('/')[0]\n",
        "              y.append(layers[name])\n",
        "          else:\n",
        "            name = layer.input.name.split(':')[0].split('/')[0]\n",
        "            y = layers[name]\n",
        "          y = layer(y)\n",
        "          layers[layer.name] = y\n",
        "\n",
        "        return y\n",
        "        \n",
        "\n",
        "\n",
        "class Discriminator:\n",
        "  \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        model = self.layers\n",
        "        model.append(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.append(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.append(InstanceNormalization())\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.append(InstanceNormalization())\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.append(InstanceNormalization())\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dropout(0.25))\n",
        "        model.append(Flatten())\n",
        "        model.append(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y = x\n",
        "        for layer in self.layers:\n",
        "            y = layer(y)\n",
        "            \n",
        "        return y\n",
        "  \n",
        "def SelfGAN():\n",
        "    \n",
        "    G_AB = Generator()\n",
        "    G_BA = Generator()\n",
        "    D_A = Discriminator()\n",
        "    D_B = Discriminator()\n",
        "    \n",
        "    realA = Input(shape=img_shape)\n",
        "    realB = Input(shape=img_shape)\n",
        "    fakeA = Input(shape=img_shape)\n",
        "    fakeB = Input(shape=img_shape)\n",
        "    \n",
        "    # Identity gen\n",
        "    idenA = G_BA(realA)\n",
        "    idenB = G_AB(realB)\n",
        "    \n",
        "    # GAN validity\n",
        "    genA = G_BA(realB)\n",
        "    genB = G_AB(realA)\n",
        "    genA = Lambda(lambda x: x*1.0, name='genA')(genA)\n",
        "    genB = Lambda(lambda x: x*1.0, name='genB')(genB)\n",
        "    validity_genA = D_A(genA)\n",
        "    validity_realA = D_A(realA)\n",
        "    validity_fakeA = D_A(fakeA)\n",
        "    validity_genB = D_B(genB)\n",
        "    validity_realB = D_B(realB)\n",
        "    validity_fakeB = D_B(fakeB)\n",
        "\n",
        "    # Cycle gen\n",
        "    recA = G_BA(genB)\n",
        "    recB = G_AB(genA)\n",
        "    \n",
        "    # compute loss\n",
        "    criterion_GAN = Lambda(lambda x: keras.losses.mean_squared_error(x[0], x[1]))\n",
        "    criterion_cycle = Lambda(lambda x: keras.losses.mean_absolute_error(x[0], x[1]))\n",
        "    criterion_identity = Lambda(lambda x: keras.losses.mean_absolute_error(x[0], x[1]))\n",
        "    \n",
        "    # Identity loss\n",
        "    loss_id_A = criterion_identity([Flatten()(idenA), Flatten()(realA)])\n",
        "    loss_id_B = criterion_identity([Flatten()(idenB), Flatten()(realB)])\n",
        "\n",
        "    loss_identity = Lambda(lambda x: (x[0]+x[1])/2, name='identity_loss')([loss_id_A, loss_id_B])\n",
        "    \n",
        "    valid = Input(shape=(1,))\n",
        "    fake = Input(shape=(1,))\n",
        "    # Self GAN loss\n",
        "    \n",
        "    # loss A2B\n",
        "    gen_loss = criterion_GAN([validity_genA, valid])\n",
        "    real_loss = criterion_GAN([validity_realA, valid])\n",
        "    fake_loss = criterion_GAN([validity_fakeA, fake])\n",
        "    \n",
        "    v_g = Lambda(lambda x: K.abs(1 - K.mean(x)))(validity_genA)\n",
        "    v_r = Lambda(lambda x: K.abs(1 - K.mean(x)))(validity_realA)\n",
        "    v_f = Lambda(lambda x: K.mean(x))(validity_fakeA)\n",
        "    v_sum = Lambda(lambda x: x[0]+x[1]+x[2])([v_g,v_r,v_f])\n",
        "    s_lossA = Lambda(lambda x: x[2]*x[1]/x[0] \\\n",
        "                            + x[4]*x[3]/x[0] \\\n",
        "                            + x[6]*x[5]/x[0])([v_sum, v_r, real_loss, v_g, gen_loss, v_f, fake_loss])\n",
        "    \n",
        "    # loss B2A\n",
        "    gen_loss = criterion_GAN([validity_genB, valid])\n",
        "    real_loss = criterion_GAN([validity_realB, valid])\n",
        "    fake_loss = criterion_GAN([validity_fakeB, fake])\n",
        "    \n",
        "    v_g = Lambda(lambda x: K.abs(1 - K.mean(x)))(validity_genB)\n",
        "    v_r = Lambda(lambda x: K.abs(1 - K.mean(x)))(validity_realB)\n",
        "    v_f = Lambda(lambda x: K.mean(x))(validity_fakeB)\n",
        "    v_sum = Lambda(lambda x: x[0]+x[1]+x[2])([v_g,v_r,v_f])\n",
        "    s_lossB = Lambda(lambda x: x[2]*x[1]/x[0] \\\n",
        "                            + x[4]*x[3]/x[0] \\\n",
        "                            + x[6]*x[5]/x[0])([v_sum, v_r, real_loss, v_g, gen_loss, v_f, fake_loss])\n",
        "    \n",
        "    s_loss = Lambda(lambda x: (x[0]+x[1])/2, name='self_loss')([s_lossA, s_lossB])\n",
        "    \n",
        "    # Cycle loss\n",
        "    loss_cycle_A = criterion_cycle([Flatten()(recA), Flatten()(realA)])\n",
        "    loss_cycle_B = criterion_cycle([Flatten()(recB), Flatten()(realB)])\n",
        "\n",
        "    loss_cycle = Lambda(lambda x: (x[0]+x[1])/2, name='cycle_loss')([loss_cycle_A , loss_cycle_B])\n",
        "    \n",
        "    def loss_All(x, lambda_cyc=10, lambda_id=1):\n",
        "      loss_s, loss_cycle, loss_identity = x\n",
        "      return loss_s + \\\n",
        "             lambda_cyc * loss_cycle + \\\n",
        "             lambda_id * loss_identity\n",
        "    \n",
        "    all_loss = Lambda(loss_All,\n",
        "                      arguments={'lambda_cyc':lambda_cyc, \n",
        "                                 'lambda_id':lambda_id})([s_loss, \n",
        "                                                          loss_cycle, \n",
        "                                                          loss_identity])\n",
        "    \n",
        "    return Model([realA, realB, fakeA, fakeB, valid, fake], [all_loss])\n",
        "  \n",
        "def sample_images(model, epoch, imgA, imgB, last_imgA, last_imgB, valid, fake):\n",
        "  \n",
        "    ret = model.predict([imgA, imgB, last_imgA, last_imgB, valid, fake])\n",
        "    imgA = imgA[:6].transpose(1,0,2,3).reshape((imgA.shape[1],-1,imgA.shape[-1]))\n",
        "    imgB = imgB[:6].transpose(1,0,2,3).reshape((imgB.shape[1],-1,imgB.shape[-1]))\n",
        "    fakeB = ret[-1][:6].transpose(1,0,2,3).reshape((ret[-1].shape[1],-1,ret[-1].shape[-1]))\n",
        "    fakeA = ret[-2][:6].transpose(1,0,2,3).reshape((ret[-2].shape[1],-1,ret[-2].shape[-1]))\n",
        "    \n",
        "    gen_imgs = np.concatenate([imgA, fakeB, imgB, fakeA])\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "    cnt = 0\n",
        "    axs.imshow(gen_imgs)\n",
        "    axs.axis('off')\n",
        "    fig.savefig(\"images/%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lipEQUtOX_UA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function override\n",
        "from tensorflow.contrib.tpu.python.tpu.keras_support import TPUFunction\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.estimator import model_fn as model_fn_lib \n",
        "ModeKeys = model_fn_lib.ModeKeys\n",
        "\n",
        "def extra_outputs(self):\n",
        "  outputs = []\n",
        "  sort_names = ['self_loss', 'cycle_loss', 'genA', 'genB']\n",
        "  for name in sort_names:\n",
        "    for layer in self.layers:\n",
        "      if name in layer.name:\n",
        "        outputs.append(layer.output)\n",
        "  return outputs\n",
        "\n",
        "def _make_predict_function(self):\n",
        "  if not hasattr(self, 'predict_function'):\n",
        "    self.predict_function = None\n",
        "  if self.predict_function is None:\n",
        "    inputs = self._feed_inputs\n",
        "    # Gets network outputs. Does not update weights.\n",
        "    # Does update the network states.\n",
        "    kwargs = getattr(self, '_function_kwargs', {})\n",
        "    with K.name_scope(ModeKeys.PREDICT):\n",
        "      self.predict_function = K.function(\n",
        "          inputs,\n",
        "          self.outputs+extra_outputs(self),\n",
        "          updates=self.state_updates,\n",
        "          name='predict_function',\n",
        "          **kwargs)\n",
        "      \n",
        "def _make_fit_function(self):\n",
        "  metrics_tensors = [\n",
        "      self._all_stateful_metrics_tensors[m] for m in self.metrics_names[1:]\n",
        "  ]\n",
        "  self._make_train_function_helper(\n",
        "      '_fit_function', [self.total_loss] + metrics_tensors + extra_outputs(self))\n",
        "  \n",
        "Model._make_predict_function = _make_predict_function\n",
        "Model._make_fit_function = _make_fit_function\n",
        "\n",
        "def _process_outputs(self, outfeed_outputs):\n",
        "    \"\"\"Processes the outputs of a model function execution.\n",
        "    Args:\n",
        "      outfeed_outputs: The sharded outputs of the TPU computation.\n",
        "    Returns:\n",
        "      The aggregated outputs of the TPU computation to be used in the rest of\n",
        "      the model execution.\n",
        "    \"\"\"\n",
        "    # TODO(xiejw): Decide how to reduce outputs, or discard all but first.\n",
        "    if self.execution_mode == ModeKeys.PREDICT:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "\n",
        "      return [np.concatenate(group) for group in outputs]\n",
        "    else:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "      \n",
        "      ret = []\n",
        "      for group in outputs:\n",
        "        if len(group[0].shape) > 0:\n",
        "          ret.append(np.concatenate(group))\n",
        "        else:\n",
        "          ret.append(group[0])\n",
        "      return ret\n",
        "    \n",
        "TPUFunction._process_outputs = _process_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8kXVRyfpz2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "model = SelfGAN()\n",
        "model.compile(loss='mae',optimizer=optimizer)\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "def initialize_uninitialized_variables():\n",
        "    sess = K.get_session()\n",
        "    uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "    init_op = tf.variables_initializer(\n",
        "        [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        "    )\n",
        "    sess.run(init_op)\n",
        "initialize_uninitialized_variables()\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "\n",
        "bufferA = ReplayBuffer()\n",
        "bufferB = ReplayBuffer()\n",
        "last_imgA = np.ones((batch_size,)+img_shape)\n",
        "last_imgB = -np.ones((batch_size,)+img_shape)\n",
        "loss_zeros = np.zeros((batch_size,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly2F41ptrog1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Init tpu model\n",
        "train_outputs = model.train_on_batch([last_imgA, last_imgB, last_imgA, last_imgB, valid, fake], [loss_zeros])\n",
        "predict_output = model.predict([last_imgA, last_imgB, last_imgA, last_imgB, valid, fake])\n",
        "\n",
        "dataLoader = DataLoader(ImageDataset('data/horse2zebra'), batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVjnI8dKspOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  \n",
        "    for i, (imgA, imgB) in enumerate(dataLoader):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of new images\n",
        "\n",
        "        outputs = model.train_on_batch([imgA, imgB, last_imgA, last_imgB, valid, fake], [loss_zeros])\n",
        "        all_loss = outputs[0]/8\n",
        "        self_loss = np.mean(outputs[1])/(batch_size/8)\n",
        "        cycle_loss = np.mean(outputs[2])/(batch_size/8)\n",
        "        identity_loss = np.mean(outputs[3])/(batch_size/8)\n",
        "        last_imgA = bufferA.push_and_pop(outputs[-2])\n",
        "        last_imgB = bufferB.push_and_pop(outputs[-1])\n",
        "        # Plot the progress\n",
        "        if i % 25 == 0:\n",
        "            sys.stdout.flush()\n",
        "            print (\"\\r[Epoch %d/%d] [Batch %d/%d]  [All loss: %f  self loss: %f cycle loss: %f  iden loss: %f]\" % (epoch, epochs, i,\n",
        "                                                                            len(dataLoader), all_loss,\n",
        "                                                                            self_loss, cycle_loss, identity_loss),end='')\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if (epoch*len(dataLoader) + i) % sample_interval == 0:\n",
        "            sample_images(model, epoch*len(dataLoader) + i, imgA, imgB, last_imgA, last_imgB, valid, fake)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}