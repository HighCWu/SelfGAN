{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_gan_keras_tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mUaJMUDUezt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Self GAN Keras TPU\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/HighCWu/SelfGAN/blob/master/implementations/gan/self_gan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/HighCWu/SelfGAN/blob/master/implementations/gan/self_gan_keras_tpu.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "_sFEKpmpesjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install 'tensorflow>1.12,<2.0' -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIQn0pnWfvoj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare"
      ]
    },
    {
      "metadata": {
        "id": "psbNazmKfpFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.python.keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 100\n",
        "batch_size = 64\n",
        "sample_interval = 1000\n",
        "epochs = 200000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjDp0s5ZgqlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "  \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        model = self.layers\n",
        "        model.append(Dense(256, input_dim=latent_dim))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(Dense(512))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(Dense(1024))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(BatchNormalization(momentum=0.8))\n",
        "        model.append(Dense(np.prod(img_shape), activation='tanh'))\n",
        "        model.append(Reshape(img_shape, name='output'))\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        y = x\n",
        "        for layer in self.layers:\n",
        "            y = layer(y)\n",
        "        \n",
        "        return y\n",
        "\n",
        "class Discriminator:\n",
        "  \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        model = self.layers\n",
        "        model.append(Flatten(input_shape=img_shape))\n",
        "        model.append(Dense(512))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dense(256))\n",
        "        model.append(LeakyReLU(alpha=0.2))\n",
        "        model.append(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y = x\n",
        "        for layer in self.layers:\n",
        "            y = layer(y)\n",
        "            \n",
        "        return y\n",
        "  \n",
        "def SelfGAN():\n",
        "    \n",
        "    generator = Generator()\n",
        "    discriminator = Discriminator()\n",
        "    \n",
        "    real_img = Input(shape=img_shape)\n",
        "    fake_img = Input(shape=img_shape)\n",
        "    \n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    gen_img = generator(noise)\n",
        "    \n",
        "    validity_gen = discriminator(gen_img)\n",
        "    validity_real = discriminator(real_img)\n",
        "    validity_fake = discriminator(fake_img)\n",
        "    \n",
        "    # compute loss\n",
        "    adversarial_loss = Lambda(lambda x: keras.losses.binary_crossentropy(x[0], x[1]))\n",
        "    \n",
        "    \n",
        "    valid = Input(shape=(1,))\n",
        "    fake = Input(shape=(1,))\n",
        "    gen_loss = adversarial_loss([validity_gen, valid])\n",
        "    real_loss = adversarial_loss([validity_real, valid])\n",
        "    fake_loss = adversarial_loss([validity_fake, fake])\n",
        "    gen_loss = Lambda(lambda x: x*1.0, name='gen_loss')(gen_loss)\n",
        "    real_loss = Lambda(lambda x: x*1.0, name='real_loss')(real_loss)\n",
        "    fake_loss = Lambda(lambda x: x*1.0, name='fake_loss')(fake_loss)\n",
        "    \n",
        "    v_g = Lambda(lambda x: 1 - K.mean(x))(validity_gen)\n",
        "    v_r = Lambda(lambda x: 1 - K.mean(x))(validity_real)\n",
        "    v_f = Lambda(lambda x: K.mean(x))(validity_fake)\n",
        "    v_sum = Lambda(lambda x: x[0]+x[1]+x[2])([v_g,v_r,v_f])\n",
        "    s_loss = Lambda(lambda x: x[2]*x[1]/x[0] \\\n",
        "                            + x[4]*x[3]/x[0] \\\n",
        "                            + x[6]*x[5]/x[0])([v_sum, v_r, real_loss, v_g, gen_loss, v_f, fake_loss])\n",
        "    \n",
        "    return Model([noise, real_img, fake_img, valid, fake], [s_loss])\n",
        "  \n",
        "def sample_images(model, epoch):\n",
        "    r = 5\n",
        "    c = 5\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = model.predict([noise, last_imgs, last_imgs, valid, fake])[-1][:r*c]\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lipEQUtOX_UA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function override\n",
        "from tensorflow.contrib.tpu.python.tpu.keras_support import TPUFunction\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.estimator import model_fn as model_fn_lib \n",
        "ModeKeys = model_fn_lib.ModeKeys\n",
        "\n",
        "def extra_outputs(self):\n",
        "  outputs = []\n",
        "  for layer in self.layers:\n",
        "    if 'loss' in layer.name:\n",
        "      outputs.append(layer.output)\n",
        "  for layer in self.layers:\n",
        "    if 'output' in layer.name:\n",
        "      outputs.append(layer.output)\n",
        "  return outputs\n",
        "\n",
        "def _make_predict_function(self):\n",
        "  if not hasattr(self, 'predict_function'):\n",
        "    self.predict_function = None\n",
        "  if self.predict_function is None:\n",
        "    inputs = self._feed_inputs\n",
        "    # Gets network outputs. Does not update weights.\n",
        "    # Does update the network states.\n",
        "    kwargs = getattr(self, '_function_kwargs', {})\n",
        "    with K.name_scope(ModeKeys.PREDICT):\n",
        "      self.predict_function = K.function(\n",
        "          inputs,\n",
        "          self.outputs+extra_outputs(self),\n",
        "          updates=self.state_updates,\n",
        "          name='predict_function',\n",
        "          **kwargs)\n",
        "      \n",
        "def _make_fit_function(self):\n",
        "  metrics_tensors = [\n",
        "      self._all_stateful_metrics_tensors[m] for m in self.metrics_names[1:]\n",
        "  ]\n",
        "  self._make_train_function_helper(\n",
        "      '_fit_function', [self.total_loss] + metrics_tensors + extra_outputs(self))\n",
        "  \n",
        "Model._make_predict_function = _make_predict_function\n",
        "Model._make_fit_function = _make_fit_function\n",
        "\n",
        "def _process_outputs(self, outfeed_outputs):\n",
        "    \"\"\"Processes the outputs of a model function execution.\n",
        "    Args:\n",
        "      outfeed_outputs: The sharded outputs of the TPU computation.\n",
        "    Returns:\n",
        "      The aggregated outputs of the TPU computation to be used in the rest of\n",
        "      the model execution.\n",
        "    \"\"\"\n",
        "    # TODO(xiejw): Decide how to reduce outputs, or discard all but first.\n",
        "    if self.execution_mode == ModeKeys.PREDICT:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "\n",
        "      return [np.concatenate(group) for group in outputs]\n",
        "    else:\n",
        "      outputs = [[] for _ in range(len(self._outfeed_spec))]\n",
        "      outputs_per_replica = len(self._outfeed_spec)\n",
        "\n",
        "      for i in range(self._tpu_assignment.num_towers):\n",
        "        output_group = outfeed_outputs[i * outputs_per_replica:(i + 1) *\n",
        "                                       outputs_per_replica]\n",
        "        for j in range(outputs_per_replica):\n",
        "          outputs[j].append(output_group[j])\n",
        "      \n",
        "      ret = []\n",
        "      for group in outputs:\n",
        "        if len(group[0].shape) > 0:\n",
        "          ret.append(np.concatenate(group))\n",
        "        else:\n",
        "          ret.append(group[0])\n",
        "      return ret\n",
        "    \n",
        "TPUFunction._process_outputs = _process_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8kXVRyfpz2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "model = SelfGAN()\n",
        "model.compile(loss='mae',optimizer=optimizer)\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Rescale -1 to 1\n",
        "X_train = X_train / 127.5 - 1.\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "last_imgs = np.zeros((batch_size,)+img_shape)\n",
        "s_loss_zeros = np.zeros((batch_size,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly2F41ptrog1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_uninitialized_variables():\n",
        "    sess = K.get_session()\n",
        "    uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "    init_op = tf.variables_initializer(\n",
        "        [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        "    )\n",
        "    sess.run(init_op)\n",
        "initialize_uninitialized_variables()\n",
        "\n",
        "# Init tpu model\n",
        "noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "train_outputs = model.train_on_batch([noise, last_imgs, last_imgs, valid, fake], [s_loss_zeros])\n",
        "predict_output = model.predict([noise, last_imgs, last_imgs, valid, fake])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVjnI8dKspOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Select a random batch of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "    # Generate a batch of new images\n",
        "    \n",
        "    outputs = model.train_on_batch([noise, imgs, last_imgs, valid, fake], [s_loss_zeros])\n",
        "    s_loss = outputs[0]/8\n",
        "    gen_loss = np.mean(outputs[2])/(batch_size/8)\n",
        "    real_loss = np.mean(outputs[1])/(batch_size/8)\n",
        "    fake_loss = np.mean(outputs[3])/(batch_size/8)\n",
        "    last_imgs = outputs[-1]\n",
        "    \n",
        "    # Plot the progress\n",
        "    if epoch % 200 == 0:\n",
        "        sys.stdout.flush()\n",
        "        print (\"\\r%d [S loss: %f  G loss: %f R loss: %f  F loss: %f]\" % (epoch, s_loss,\n",
        "                                                                        gen_loss, real_loss, fake_loss),end='')\n",
        "\n",
        "    # If at save interval => save generated image samples\n",
        "    if epoch % sample_interval == 0:\n",
        "        sample_images(model, epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}